{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = [\n",
    "    'poi', 'salary', 'bonus', 'long_term_incentive', 'deferred_income',\n",
    "    'deferral_payments', 'loan_advances', 'other', 'expenses', 'director_fees',\n",
    "    'total_payments', 'exercised_stock_options', 'restricted_stock',\n",
    "    'restricted_stock_deferred', 'total_stock_value',\n",
    "    'from_poi_to_this_person', 'shared_receipt_with_poi', 'to_messages',\n",
    "    'from_this_person_to_poi', 'from_messages'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, METTS MARK to GLISAN JR BEN F\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null bool\n",
      "salary                       95 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "other                        93 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "dtypes: bool(1), float64(19)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"rb\") as data_file:\n",
    "    enron_data = pickle.load(data_file)\n",
    "\n",
    "enron_data = pd.DataFrame.from_dict(enron_data)\n",
    "enron_data = enron_data.T\n",
    "enron_data = enron_data[features_list]\n",
    "#Data Cleaning\n",
    "enron_data.replace(to_replace='NaN', value=np.nan, inplace=True)\n",
    "#enron_data.count().sort_values()\n",
    "enron_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Data Points (People): 145\n",
      "Number of features:  20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_frame = enron_data.drop([\"poi\"], axis=1)\n",
    "temp_frame[temp_frame.isnull().all(axis=1)]\n",
    "\n",
    "#LOCKHART EUGENE E has all values NaN, so we remove him\n",
    "enron_data = enron_data.drop([\"LOCKHART EUGENE E\"], axis=0)\n",
    "\n",
    "print (\"Number of Data Points (People):\", len(enron_data['bonus']))\n",
    "print (\"Number of features: \", enron_data.shape[1])\n",
    "type(enron_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    127\n",
      "True      18\n",
      "Name: poi, dtype: int64\n",
      "Amount of NaN values in the dataset:  1304\n"
     ]
    }
   ],
   "source": [
    "#Printing no. of Poi and Non-poi\n",
    "poi_nonpoi = enron_data.poi.value_counts()\n",
    "print (poi_nonpoi)\n",
    "type(enron_data)\n",
    "print (\"Amount of NaN values in the dataset: \", enron_data.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>from_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>False</td>\n",
       "      <td>365788.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>94299.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1061827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>585062.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>False</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>594.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>False</td>\n",
       "      <td>170941.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-400729.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12961.0</td>\n",
       "      <td>78552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211725.0</td>\n",
       "      <td>4890344.0</td>\n",
       "      <td>1788391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6678735.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>594.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651850.0</td>\n",
       "      <td>386335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1038185.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>True</td>\n",
       "      <td>243293.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>-3117011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11350.0</td>\n",
       "      <td>34039.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288682.0</td>\n",
       "      <td>5538001.0</td>\n",
       "      <td>853064.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6391065.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poi    salary      bonus  long_term_incentive  \\\n",
       "METTS MARK        False  365788.0   600000.0                  0.0   \n",
       "BAXTER JOHN C     False  267102.0  1200000.0            1586055.0   \n",
       "ELLIOTT STEVEN    False  170941.0   350000.0                  0.0   \n",
       "CORDES WILLIAM R  False       0.0        0.0                  0.0   \n",
       "HANNON KEVIN P     True  243293.0  1500000.0            1617011.0   \n",
       "\n",
       "                  deferred_income  deferral_payments  loan_advances  \\\n",
       "METTS MARK                    0.0                0.0            0.0   \n",
       "BAXTER JOHN C          -1386055.0          1295738.0            0.0   \n",
       "ELLIOTT STEVEN          -400729.0                0.0            0.0   \n",
       "CORDES WILLIAM R              0.0                0.0            0.0   \n",
       "HANNON KEVIN P         -3117011.0                0.0            0.0   \n",
       "\n",
       "                      other  expenses  director_fees  total_payments  \\\n",
       "METTS MARK           1740.0   94299.0            0.0       1061827.0   \n",
       "BAXTER JOHN C     2660303.0   11200.0            0.0       5634343.0   \n",
       "ELLIOTT STEVEN      12961.0   78552.0            0.0        211725.0   \n",
       "CORDES WILLIAM R        0.0       0.0            0.0             0.0   \n",
       "HANNON KEVIN P      11350.0   34039.0            0.0        288682.0   \n",
       "\n",
       "                  exercised_stock_options  restricted_stock  \\\n",
       "METTS MARK                            0.0          585062.0   \n",
       "BAXTER JOHN C                   6680544.0         3942714.0   \n",
       "ELLIOTT STEVEN                  4890344.0         1788391.0   \n",
       "CORDES WILLIAM R                 651850.0          386335.0   \n",
       "HANNON KEVIN P                  5538001.0          853064.0   \n",
       "\n",
       "                  restricted_stock_deferred  total_stock_value  \\\n",
       "METTS MARK                              0.0           585062.0   \n",
       "BAXTER JOHN C                           0.0         10623258.0   \n",
       "ELLIOTT STEVEN                          0.0          6678735.0   \n",
       "CORDES WILLIAM R                        0.0          1038185.0   \n",
       "HANNON KEVIN P                          0.0          6391065.0   \n",
       "\n",
       "                  from_poi_to_this_person  shared_receipt_with_poi  \\\n",
       "METTS MARK                           38.0                    702.0   \n",
       "BAXTER JOHN C                        26.5                    594.0   \n",
       "ELLIOTT STEVEN                       26.5                    594.0   \n",
       "CORDES WILLIAM R                     10.0                     58.0   \n",
       "HANNON KEVIN P                       32.0                   1035.0   \n",
       "\n",
       "                  to_messages  from_this_person_to_poi  from_messages  \n",
       "METTS MARK              807.0                      1.0           29.0  \n",
       "BAXTER JOHN C           944.0                      6.0           41.0  \n",
       "ELLIOTT STEVEN          944.0                      6.0           41.0  \n",
       "CORDES WILLIAM R        764.0                      0.0           12.0  \n",
       "HANNON KEVIN P         1045.0                     21.0           32.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#According to the financial data from FindLaw, NaN values represent values of 0 but not the missing value. \n",
    "#Replace all NaNs with 0.\n",
    "f1 = ['poi', 'salary', 'bonus', 'long_term_incentive', 'deferred_income',\n",
    "    'deferral_payments', 'loan_advances', 'other', 'expenses', 'director_fees',\n",
    "    'total_payments', 'exercised_stock_options', 'restricted_stock',\n",
    "    'restricted_stock_deferred', 'total_stock_value']\n",
    "df1 = enron_data[f1]\n",
    "df1.fillna(value = 0, inplace = True)\n",
    "\n",
    "#NaN values in email features mean the information is missing. \n",
    "#Impute the missing values with median of each class.\n",
    "\n",
    "f2 = ['from_poi_to_this_person', 'shared_receipt_with_poi', 'to_messages',\n",
    "    'from_this_person_to_poi', 'from_messages']\n",
    "df2 = enron_data[f2]\n",
    "from sklearn.impute import SimpleImputer\n",
    "#imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "#imp.fit_transform(df2)\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median', copy=False)\n",
    "imp.fit_transform(df2)\n",
    "\n",
    "result = pd.concat([df1, df2], axis=1, sort=False)\n",
    "enron_data = result\n",
    "enron_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2: Remove outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-09aa5ac39d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### Extract features and labels from dataset for local testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargetFeatureSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "#my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "#dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
